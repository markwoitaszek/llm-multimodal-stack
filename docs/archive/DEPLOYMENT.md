# Deployment Guide

Complete deployment guide for the Multimodal LLM Stack on RTX 3090 GPU servers.

## Quick Start

```bash
# 1. Clone repository
git clone <repo-url>
cd llm-multimodal-stack

# 2. Setup environment
./scripts/setup.sh

# 3. Start the stack
docker-compose up -d

# 4. Check health
./scripts/health-check.sh

# 5. Access services
open http://localhost:3000  # Web interface
```

## Deployment Options

### 1. Development Deployment

```bash
# Start with development settings
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# Features:
# - Hot reload for code changes
# - Debug logging enabled
# - Exposed database ports
# - Development tools included
```

### 2. Production Deployment

```bash
# Deploy to production
./scripts/deploy-production.sh

# Features:
# - Optimized performance settings
# - SSL/TLS certificates
# - Nginx reverse proxy
# - Monitoring with Prometheus/Grafana
# - Redis caching
# - Enhanced security
```

### 3. Enhanced PostgreSQL Deployment

```bash
# Deploy with PostgREST API and pgAdmin
docker-compose -f docker-compose.yml -f docker-compose.enhanced-postgres.yml up -d

# Features:
# - Auto-generated REST API
# - Database management UI
# - Enhanced PostgreSQL configuration
```

## Hardware Requirements

### Minimum Requirements
- **GPU**: NVIDIA RTX 3060 (12GB VRAM) or equivalent
- **CPU**: 8 cores, 3.0GHz+
- **RAM**: 32GB system memory
- **Storage**: 500GB SSD
- **Network**: 1Gbps connection

### Recommended (RTX 3090)
- **GPU**: NVIDIA RTX 3090 (24GB VRAM)
- **CPU**: 12+ cores, 3.5GHz+
- **RAM**: 64GB system memory
- **Storage**: 2TB NVMe SSD (optimized with seismic-nvme)
- **Network**: 10Gbps connection

### Storage Layout (with seismic-nvme)
```
/mnt/nvme/
├── qdrant/          # Vector database
├── postgres/        # Relational database
├── minio/           # Object storage
├── cache/           # Model cache
├── grafana/         # Monitoring data
├── prometheus/      # Metrics data
└── redis/           # Session cache
```

## Pre-Installation Setup

### 1. NVIDIA Docker Setup

```bash
# Install NVIDIA Docker runtime
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Verify GPU access
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi
```

### 2. Seismic NVMe Optimization (Optional)

If you have the seismic-nvme optimization setup:

```bash
# Run the NVMe optimization (if available)
cd ../seismic-nvme
./quick-deploy.sh

# Verify NVMe mount
df -h | grep nvme
```

### 3. System Optimization

```bash
# Increase file limits
echo "* soft nofile 65536" | sudo tee -a /etc/security/limits.conf
echo "* hard nofile 65536" | sudo tee -a /etc/security/limits.conf

# Optimize kernel parameters
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
echo "net.core.somaxconn=65535" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# Install performance monitoring tools
sudo apt-get update
sudo apt-get install -y htop iotop nvidia-ml-py3
```

## Configuration

### 1. Environment Variables

Copy and customize the environment file:

```bash
cp env.example .env

# Key settings to review:
# - VLLM_MODEL: Choose appropriate model for your GPU
# - CUDA_VISIBLE_DEVICES: GPU selection
# - Storage paths: Update for NVMe if available
# - API keys: Will be auto-generated by setup script
```

### 2. Model Selection

Choose models based on your GPU memory:

**RTX 3090 (24GB VRAM) Recommendations:**
```bash
# For maximum performance
VLLM_MODEL=meta-llama/Llama-2-7b-chat-hf

# For balanced performance/memory
VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.1

# For development/testing
VLLM_MODEL=microsoft/DialoGPT-medium
```

**RTX 3060/3070 (8-12GB VRAM):**
```bash
# Recommended for smaller GPUs
VLLM_MODEL=microsoft/DialoGPT-large
VLLM_MODEL=distilgpt2
```

### 3. Performance Tuning

Adjust GPU memory utilization:

```yaml
# In docker-compose.yml, modify vLLM command:
command: >
  --model ${VLLM_MODEL}
  --gpu-memory-utilization 0.85  # Adjust based on your needs
  --max-model-len 4096
  --dtype auto
```

## Deployment Steps

### Step 1: Initial Setup

```bash
# Run setup script
./scripts/setup.sh

# This will:
# - Create directory structure
# - Generate secure passwords
# - Configure storage paths
# - Set up GPU support
```

### Step 2: Start Infrastructure

```bash
# Start database and storage services first
docker-compose up -d postgres qdrant minio

# Wait for services to initialize
sleep 30

# Check infrastructure health
curl http://localhost:6333/health    # Qdrant
curl http://localhost:9000/minio/health/live  # MinIO
docker-compose exec postgres pg_isready -U postgres  # PostgreSQL
```

### Step 3: Start Application Services

```bash
# Start compute services
docker-compose up -d vllm litellm

# Wait for models to load (this can take several minutes)
sleep 120

# Start processing services
docker-compose up -d multimodal-worker retrieval-proxy

# Start web interface
docker-compose up -d openwebui
```

### Step 4: Verify Deployment

```bash
# Run comprehensive health check
./scripts/health-check.sh

# Test basic functionality
./scripts/test-multimodal.sh

# Check performance
./scripts/benchmark.sh
```

## Production Deployment

### Step 1: Production Setup

```bash
# Deploy with production configuration
./scripts/deploy-production.sh

# This includes:
# - SSL certificate generation
# - Nginx reverse proxy
# - Monitoring stack (Prometheus/Grafana)
# - Redis caching
# - Performance optimizations
```

### Step 2: SSL Certificate Setup

For production with custom domain:

```bash
# Install certbot for Let's Encrypt
sudo apt-get install certbot

# Generate SSL certificate
sudo certbot certonly --standalone -d your-domain.com

# Update nginx configuration
sudo cp certs/your-domain.com.pem certs/cert.pem
sudo cp certs/your-domain.com-key.pem certs/key.pem

# Restart nginx
docker-compose restart nginx
```

### Step 3: Firewall Configuration

```bash
# Configure UFW firewall
sudo ufw enable
sudo ufw allow ssh
sudo ufw allow 80/tcp   # HTTP
sudo ufw allow 443/tcp  # HTTPS

# Optional: Allow direct API access
sudo ufw allow 4000/tcp  # LiteLLM API
sudo ufw allow 8001/tcp  # Multimodal Worker API
sudo ufw allow 8002/tcp  # Retrieval Proxy API
```

### Step 4: Monitoring Setup

Access monitoring interfaces:

- **Grafana**: http://your-domain:3001
- **Prometheus**: http://your-domain:9090
- **MinIO Console**: http://your-domain:9001

Default credentials are in `.env.prod` file.

## Scaling and High Availability

### Horizontal Scaling

```bash
# Scale processing services
docker-compose up -d --scale multimodal-worker=3
docker-compose up -d --scale retrieval-proxy=2

# Scale with different GPU assignments
CUDA_VISIBLE_DEVICES=0,1 docker-compose up -d --scale multimodal-worker=2
```

### Load Balancing

Add load balancer configuration to `configs/nginx.conf`:

```nginx
upstream multimodal-workers {
    server multimodal-worker-1:8001;
    server multimodal-worker-2:8001;
    server multimodal-worker-3:8001;
}
```

### Database Replication

For high availability, consider PostgreSQL streaming replication:

```yaml
# docker-compose.ha.yml
services:
  postgres-primary:
    # Primary database configuration
  
  postgres-replica:
    # Read replica configuration
```

## Backup and Recovery

### Automated Backups

```bash
# Create backup script
cat > scripts/backup.sh << 'EOF'
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/multimodal-stack/$DATE"
mkdir -p "$BACKUP_DIR"

# Backup PostgreSQL
docker-compose exec -T postgres pg_dump -U postgres multimodal > "$BACKUP_DIR/postgres.sql"

# Backup Qdrant
docker run --rm -v llm-multimodal-stack_qdrant_data:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/qdrant.tar.gz -C /data .

# Backup MinIO
docker run --rm -v llm-multimodal-stack_minio_data:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/minio.tar.gz -C /data .

echo "Backup completed: $BACKUP_DIR"
EOF

chmod +x scripts/backup.sh

# Setup daily backups
echo "0 2 * * * /path/to/llm-multimodal-stack/scripts/backup.sh" | crontab -
```

### Recovery Procedure

```bash
# Stop services
docker-compose down

# Restore PostgreSQL
cat backup/postgres.sql | docker-compose exec -T postgres psql -U postgres -d multimodal

# Restore Qdrant
docker run --rm -v llm-multimodal-stack_qdrant_data:/data -v ./backup:/backup alpine tar xzf /backup/qdrant.tar.gz -C /data

# Restore MinIO
docker run --rm -v llm-multimodal-stack_minio_data:/data -v ./backup:/backup alpine tar xzf /backup/minio.tar.gz -C /data

# Restart services
docker-compose up -d
```

## Troubleshooting

### Common Issues

1. **GPU Out of Memory**
   ```bash
   # Reduce GPU memory utilization
   sed -i 's/gpu-memory-utilization 0.8/gpu-memory-utilization 0.6/' docker-compose.yml
   docker-compose restart vllm multimodal-worker
   ```

2. **Slow Model Loading**
   ```bash
   # Pre-download models
   docker-compose run --rm multimodal-worker python -c "
   from transformers import CLIPModel; 
   CLIPModel.from_pretrained('openai/clip-vit-base-patch32')
   "
   ```

3. **Database Connection Issues**
   ```bash
   # Reset database
   docker-compose down
   docker volume rm llm-multimodal-stack_postgres_data
   docker-compose up -d postgres
   ```

### Log Analysis

```bash
# View all service logs
docker-compose logs -f

# View specific service logs
docker-compose logs -f multimodal-worker

# Search for errors
docker-compose logs | grep -i error

# Export logs for analysis
docker-compose logs > logs_$(date +%Y%m%d).txt
```

### Performance Monitoring

```bash
# Monitor GPU usage
watch -n 1 nvidia-smi

# Monitor system resources
htop

# Monitor Docker containers
docker stats

# Check disk usage
df -h
du -sh /var/lib/docker/volumes/*
```

## Maintenance

### Regular Maintenance Tasks

```bash
# Weekly maintenance script
cat > scripts/weekly-maintenance.sh << 'EOF'
#!/bin/bash
echo "Running weekly maintenance..."

# Clean up Docker
docker system prune -f
docker volume prune -f

# Update images
docker-compose pull

# Restart services
docker-compose restart

# Run health checks
./scripts/health-check.sh

echo "Maintenance completed"
EOF
```

### Updates

```bash
# Update to latest version
git pull origin main
docker-compose pull
docker-compose up -d --build

# Verify update
./scripts/health-check.sh
```

This deployment guide provides comprehensive instructions for setting up the Multimodal LLM Stack in various configurations, from development to production environments.
