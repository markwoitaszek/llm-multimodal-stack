# GPU optimization override
# Use with: docker compose -f compose.yml -f compose.gpu.yml up

version: '3.8'

services:
  vllm:
    image: vllm/vllm-openai:v0.6.3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0,1}
      - NVIDIA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0,1}
    command: [
      "--model", "microsoft/DialoGPT-small",
      "--host", "0.0.0.0",
      "--port", "8000",
      "--gpu-memory-utilization", "0.8",
      "--max-model-len", "512",
      "--dtype", "auto",
      "--tensor-parallel-size", "2"
    ]
  
  multimodal-worker:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-1}
      - NVIDIA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-1}